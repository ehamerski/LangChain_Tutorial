{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048876d8-c05f-45fd-883c-f756aee5cfc4",
   "metadata": {},
   "source": [
    "# Lesson 4: Question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad214456-a809-4f50-8d4a-7a418c8e47f1",
   "metadata": {},
   "source": [
    "![](./images/rag_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b666824e-a940-484f-b3f0-6b7682ef4677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Module: null prototype] { default: {} }"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import \"dotenv/config\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bee5413-fcde-4dd9-b5fb-89023203cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { loadAndSplitChunks } from \"./lib/helpers.ts\";\n",
    "\n",
    "const splitDocs = await loadAndSplitChunks({\n",
    "    chunkSize: 1536,\n",
    "    chunkOverlap: 128\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e86ff7-6368-4442-8ee6-0a1a3c1b35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { initializeVectorstoreWithDocuments } from \"./lib/helpers.ts\";\n",
    "\n",
    "const vectorstore = await initializeVectorstoreWithDocuments({\n",
    "  documents: splitDocs,\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634988ed-0a57-49bc-9261-dc19fe66529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "const retriever = vectorstore.asRetriever();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b484116-7cee-4c7e-a020-183771d26125",
   "metadata": {},
   "source": [
    "# Document retrieval in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd470c94-5bec-4efe-8395-416b0a408f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnableSequence } from \"langchain/schema/runnable\";\n",
    "import { Document } from \"langchain/document\";\n",
    "\n",
    "const convertDocsToString = (documents: Document[]): string => {\n",
    "  return documents.map((document) => {\n",
    "    return `<doc>\\n${document.pageContent}\\n</doc>`\n",
    "  }).join(\"\\n\");\n",
    "};\n",
    "\n",
    "/*\n",
    "{\n",
    "question: \"What is deep learning?\"\n",
    "}\n",
    "*/\n",
    "\n",
    "const documentRetrievalChain = RunnableSequence.from([\n",
    "    (input) => input.question,\n",
    "    retriever,\n",
    "    convertDocsToString\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4476713f-5285-4d2f-9126-d30ee9825090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doc>\n",
      "course information handout. So let me just say a few words about parts of these. On the \n",
      "third page, there's a section that says Online Resources.  \n",
      "Oh, okay. Louder? Actually, could you turn up the volume? Testing. Is this better? \n",
      "Testing, testing. Okay, cool. Thanks.\n",
      "</doc>\n",
      "<doc>\n",
      "of this class will not be very programming intensive, although we will do some \n",
      "programming, mostly in either MATLAB or Octave. I'll say a bit more about that later.  \n",
      "I also assume familiarity with basic probability and statistics. So most undergraduate \n",
      "statistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \n",
      "assume all of you know what random variables are, that all of you know what expectation \n",
      "is, what a variance or a random variable is. And in case of some of you, it's been a while \n",
      "since you've seen some of this material. At some of the discussion sections, we'll actually \n",
      "go over some of the prerequisites, sort of as a refresher course under prerequisite class. \n",
      "I'll say a bit more about that later as well.  \n",
      "Lastly, I also assume familiarity with basic linear algebra. And again, most undergraduate \n",
      "linear algebra courses are more than enough. So if you've taken courses like Math 51, \n",
      "103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \n",
      "gonna assume that all of you know what matrixes and vectors are, that you know how to \n",
      "multiply matrices and vectors and multiply matrix and matrices, that you know what a \n",
      "matrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. \n",
      "But if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in \n",
      "the review sections.  \n",
      "So there are a couple more logistical things I should deal with in this class. One is that, as\n",
      "</doc>\n",
      "<doc>\n",
      "material that I'm teaching in the main lectures. So machine learning is a huge field, and \n",
      "there are a few extensions that we really want to teach but didn't have time in the main \n",
      "lectures for.\n",
      "</doc>\n",
      "<doc>\n",
      "same regardless of the group size, so with a larger group, you probably — I recommend \n",
      "trying to form a team, but it's actually totally fine to do it in a smaller group if you want.  \n",
      "Student : [Inaudible] what language [inaudible]?  \n",
      "Instructor (Andrew Ng): So let's see. There is no C programming in this class other \n",
      "than any that you may choose to do yourself in your project. So all the homeworks can be \n",
      "done in MATLAB or Octave, and let's see. And I guess the program prerequisites is more \n",
      "the ability to understand big?O notation and knowledge of what a data structure, like a \n",
      "linked list or a queue or binary treatments, more so than your knowledge of C or Java \n",
      "specifically. Yeah?  \n",
      "Student : Looking at the end semester project, I mean, what exactly will you be testing \n",
      "over there? [Inaudible]?  \n",
      "Instructor (Andrew Ng) : Of the project?  \n",
      "Student : Yeah.  \n",
      "Instructor (Andrew Ng) : Yeah, let me answer that later. In a couple of weeks, I shall \n",
      "give out a handout with guidelines for the project. But for now, we should think of the \n",
      "goal as being to do a cool piece of machine learning work that will let you experience the\n",
      "</doc>\n"
     ]
    }
   ],
   "source": [
    "const results = await documentRetrievalChain.invoke({\n",
    "  question: \"What are the prerequisites for this course?\"\n",
    "});\n",
    "console.log(results);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f213b67-f7d3-4e30-9776-41b0b4ce6a10",
   "metadata": {},
   "source": [
    "# Synthesizing a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3366a1-4f80-4d4f-b49b-d7223b143d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"langchain/prompts\";\n",
    "\n",
    "const TEMPLATE_STRING = `You are an experienced researcher, \n",
    "expert at interpreting and answering questions based on provided sources.\n",
    "Using the provided context, answer the user's question \n",
    "to the best of your ability using only the resources provided. \n",
    "Be verbose!\n",
    "\n",
    "<context>\n",
    "\n",
    "{context}\n",
    "\n",
    "</context>\n",
    "\n",
    "Now, answer this question using the above context:\n",
    "\n",
    "{question}`;\n",
    "\n",
    "const answerGenerationPrompt = ChatPromptTemplate.fromTemplate(\n",
    "    TEMPLATE_STRING\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2581cfc-aec6-4600-860c-1e100d42a382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  question: \u001b[32m\"What are the prerequisites for this course?\"\u001b[39m,\n",
       "  context: \u001b[32m\"<doc>\\n\"\u001b[39m +\n",
       "    \u001b[32m\"course information handout. So let me just say a few words about parts of these. On the \\n\"\u001b[39m +\n",
       "    \u001b[32m\"third\"\u001b[39m... 3063 more characters\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { RunnableMap } from \"langchain/schema/runnable\";\n",
    "\n",
    "const runnableMap = RunnableMap.from({\n",
    "  context: documentRetrievalChain,\n",
    "  question: (input) => input.question,\n",
    "});\n",
    "\n",
    "await runnableMap.invoke({\n",
    "    question: \"What are the prerequisites for this course?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd402e-854d-448b-b402-241d9cbaedd2",
   "metadata": {},
   "source": [
    "# Augmented generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6da99c5b-08d1-4f6c-a4dd-aed004b6e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"langchain/chat_models/openai\";\n",
    "import { StringOutputParser } from \"langchain/schema/output_parser\";\n",
    "\n",
    "const model = new ChatOpenAI({\n",
    "    modelName: \"gpt-3.5-turbo-1106\"\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9699b4e1-a46c-44e2-8f13-2f6ff62f49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "const retrievalChain = RunnableSequence.from([\n",
    "  {\n",
    "    context: documentRetrievalChain,\n",
    "    question: (input) => input.question,\n",
    "  },\n",
    "  answerGenerationPrompt,\n",
    "  model,\n",
    "  new StringOutputParser(),\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8219b6ca-bf2d-4471-91f8-b3e6870ce07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the prerequisites for this course include familiarity with basic probability and statistics, as well as basic linear algebra. The instructor mentions that most undergraduate statistics classes and linear algebra courses at Stanford are more than enough to meet these prerequisites. Additionally, students are expected to know about random variables, expectations, variances, matrices, vectors, matrix multiplication, and matrix inverses. The instructor also mentions that knowledge of big-O notation and understanding of data structures like linked lists, queues, and binary trees is important for the course, rather than a specific programming language like C or Java. The instructor also alludes to the fact that some material will be reviewed in the discussion sections for those who may need a refresher.\n"
     ]
    }
   ],
   "source": [
    "const answer = await retrievalChain.invoke({\n",
    "  question: \"What are the prerequisites for this course?\"\n",
    "});\n",
    "\n",
    "console.log(answer);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d091de-c9a8-429f-8bda-d43b489cdace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the question seems to be asking for a list of items. Unfortunately, the provided context does not include any specific items or topics to list in bullet point form. Therefore, it is not possible to create a bullet point list based solely on the provided context. If there are specific items or topics you would like listed in bullet point form, please provide that information and I can certainly assist with creating the list.\n"
     ]
    }
   ],
   "source": [
    "const followupAnswer = await retrievalChain.invoke({\n",
    "  question: \"Can you list them in bullet point form?\"\n",
    "});\n",
    "\n",
    "console.log(followupAnswer);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ce99cb-ab2f-4443-93c8-a5f7c979de71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doc>\n",
      "course information handout. So let me just say a few words about parts of these. On the \n",
      "third page, there's a section that says Online Resources.  \n",
      "Oh, okay. Louder? Actually, could you turn up the volume? Testing. Is this better? \n",
      "Testing, testing. Okay, cool. Thanks.\n",
      "</doc>\n",
      "<doc>\n",
      "into four major sections. We're gonna talk about four major topics in this class, the first \n",
      "of which is supervised learning. So let me give you an example of that.  \n",
      "So suppose you collect a data set of housing prices. And one of the TAs, Dan Ramage, \n",
      "actually collected a data set for me last week to use in the example later. But suppose that \n",
      "you go to collect statistics about how much houses cost in a certain geographic area. And \n",
      "Dan, the TA, collected data from housing prices in Portland, Oregon. So what you can do \n",
      "is let's say plot the square footage of the house against the list price of the house, right, so \n",
      "you collect data on a bunch of houses. And let's say you get a data set like this with \n",
      "houses of different sizes that are listed for different amounts of money.  \n",
      "Now, let's say that I'm trying to sell a house in the same area as Portland, Oregon as \n",
      "where the data comes from. Let's say I have a house that's this size in square footage, and \n",
      "I want an algorithm to tell me about how much should I expect my house to sell for. So \n",
      "there are lots of ways to do this, and some of you may have seen elements of what I'm \n",
      "about to say before.  \n",
      "So one thing you could do is look at this data and maybe put a straight line to it. And then \n",
      "if this is my house, you may then look at the straight line and predict that my house is \n",
      "gonna go for about that much money, right? There are other decisions that we can make, \n",
      "which we'll talk about later, which is, well, what if I don't wanna put a straight line?\n",
      "</doc>\n",
      "<doc>\n",
      "joys of machine learning firsthand and really try to think about doing a publishable piece \n",
      "of work.  \n",
      "So many students will try to build a cool machine learning application. That's probably \n",
      "the most common project. Some students will try to improve state-of-the-art machine \n",
      "learning. Some of those projects are also very successful. It's a little bit harder to do. And \n",
      "there's also a smaller minority of students that will sometimes try to prove — develop the \n",
      "theory of machine learning further or try to prove theorems about machine learning. So \n",
      "they're usually great projects of all of those types with applications and machine learning \n",
      "being the most common. Anything else? Okay, cool.  \n",
      "So that was it for logistics. Let's talk about learning algorithms. So can I have the laptop \n",
      "display, please, or the projector? Actually, could you lower the big screen? Cool. This is \n",
      "amazing customer service. Thank you. I see. Okay, cool. Okay. No, that's fine. I see. \n",
      "Okay. That's cool. Thanks. Okay.  \n",
      "Big screen isn't working today, but I hope you can read things on the smaller screens out \n",
      "there. Actually, [inaudible] I think this room just got a new projector that — someone \n",
      "sent you an excited email — was it just on Friday? — saying we just got a new projector \n",
      "and they said 4,000-to-1 something or other brightness ratio. I don't know. Someone was \n",
      "very excited about the new projector in this room, but I guess we'll see that in operation \n",
      "on Wednesday.\n",
      "</doc>\n",
      "<doc>\n",
      "which we'll talk about later, which is, well, what if I don't wanna put a straight line? \n",
      "Maybe I should put a quadratic function to it. Maybe that fits the data a little bit better. \n",
      "You notice if you do that, the price of my house goes up a bit, so that'd be nice.\n",
      "</doc>\n"
     ]
    }
   ],
   "source": [
    "const docs = await documentRetrievalChain.invoke({\n",
    "  question: \"Can you list them in bullet point form?\"\n",
    "});\n",
    "\n",
    "console.log(docs);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09645f74-86ab-4c2e-b50b-78e7886798e4",
   "metadata": {},
   "source": [
    "# Adding history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d678f1d-c37c-462f-96ba-d1c84ab35482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { MessagesPlaceholder } from \"langchain/prompts\";\n",
    "\n",
    "const REPHRASE_QUESTION_SYSTEM_TEMPLATE = \n",
    "  `Given the following conversation and a follow up question, \n",
    "rephrase the follow up question to be a standalone question.`;\n",
    "\n",
    "const rephraseQuestionChainPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", REPHRASE_QUESTION_SYSTEM_TEMPLATE],\n",
    "  new MessagesPlaceholder(\"history\"),\n",
    "  [\n",
    "    \"human\", \n",
    "    \"Rephrase the following question as a standalone question:\\n{question}\"\n",
    "  ],\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18f6254b-5eaf-4867-999b-97d08f96cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "const rephraseQuestionChain = RunnableSequence.from([\n",
    "      rephraseQuestionChainPrompt,\n",
    "      new ChatOpenAI({ temperature: 0.1, modelName: \"gpt-3.5-turbo-1106\" }),\n",
    "      new StringOutputParser(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c326a7cc-d9be-432c-be10-7846d2b8e5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prerequisites for this course, as mentioned by the instructor, include familiarity with basic probability and statistics, as well as basic linear algebra. It is assumed that students have knowledge of random variables, expectation, variance, matrices, vectors, matrix multiplication, matrix inverse, and possibly eigenvectors of a matrix. The instructor also mentions that most undergraduate statistics and linear algebra courses, such as Stat 116, Math 51, 103, 113, or CS205 at Stanford, will provide the necessary background for the course. Additionally, the ability to understand big-O notation and knowledge of data structures like linked lists, queues, or binary treatments is more important than specific programming language knowledge. The instructor also emphasizes that for those who may need a refresher on these topics, there will be discussion sections to review the prerequisites.\n"
     ]
    }
   ],
   "source": [
    "import { HumanMessage, AIMessage } from \"langchain/schema\";\n",
    "\n",
    "const originalQuestion = \"What are the prerequisites for this course?\";\n",
    "\n",
    "const originalAnswer = await retrievalChain.invoke({\n",
    "  question: originalQuestion\n",
    "});\n",
    "\n",
    "console.log(originalAnswer);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b25e21c-28d0-4329-852e-b96a14c38529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Could you please list the prerequisites for this course in bullet point form?\"\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const chatHistory = [\n",
    "      new HumanMessage(originalQuestion),\n",
    "      new AIMessage(originalAnswer),\n",
    "];\n",
    "\n",
    "await rephraseQuestionChain.invoke({\n",
    "    question: \"Can you list them in bullet point form?\",\n",
    "    history: chatHistory,\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76381b8-b08f-4244-af09-e4bc836f9c88",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c325c8b5-9292-41f2-ad10-3ad0ad3df182",
   "metadata": {},
   "outputs": [],
   "source": [
    "const convertDocsToString = (documents: Document[]): string => {\n",
    "  return documents.map((document) => `<doc>\\n${document.pageContent}\\n</doc>`).join(\"\\n\");\n",
    "};\n",
    "\n",
    "const documentRetrievalChain = RunnableSequence.from([\n",
    "  (input) => input.standalone_question,\n",
    "  retriever,\n",
    "  convertDocsToString,\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5fe1d4c-9075-47d4-8451-b9bbc1115668",
   "metadata": {},
   "outputs": [],
   "source": [
    "const ANSWER_CHAIN_SYSTEM_TEMPLATE = `You are an experienced researcher, \n",
    "expert at interpreting and answering questions based on provided sources.\n",
    "Using the below provided context and chat history, \n",
    "answer the user's question to the best of \n",
    "your ability \n",
    "using only the resources provided. Be verbose!\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>`;\n",
    "\n",
    "const answerGenerationChainPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", ANSWER_CHAIN_SYSTEM_TEMPLATE],\n",
    "  new MessagesPlaceholder(\"history\"),\n",
    "  [\n",
    "    \"human\", \n",
    "    \"Now, answer this question using the previous context and chat history:\\n{standalone_question}\"\n",
    "  ]\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cb3853d-826c-4e1f-a413-9f9f0faf62fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  SystemMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"You are an experienced researcher, \\n\"\u001b[39m +\n",
       "        \u001b[32m\"expert at interpreting and answering questions based on provided\"\u001b[39m... 210 more characters,\n",
       "      additional_kwargs: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"You are an experienced researcher, \\n\"\u001b[39m +\n",
       "      \u001b[32m\"expert at interpreting and answering questions based on provided\"\u001b[39m... 210 more characters,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {}\n",
       "  },\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: { content: \u001b[32m\"How are you?\"\u001b[39m, additional_kwargs: {} },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"How are you?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: { content: \u001b[32m\"Fine, thank you!\"\u001b[39m, additional_kwargs: {} },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Fine, thank you!\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {}\n",
       "  },\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"Now, answer this question using the previous context and chat history:\\n\"\u001b[39m +\n",
       "        \u001b[32m\"Why is the sky blue?\"\u001b[39m,\n",
       "      additional_kwargs: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "    content: \u001b[32m\"Now, answer this question using the previous context and chat history:\\n\"\u001b[39m +\n",
       "      \u001b[32m\"Why is the sky blue?\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {}\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { HumanMessage, AIMessage } from \"langchain/schema\";\n",
    "await answerGenerationChainPrompt.formatMessages({\n",
    "  context: \"fake retrieved content\",\n",
    "  standalone_question: \"Why is the sky blue?\",\n",
    "  history: [\n",
    "    new HumanMessage(\"How are you?\"),\n",
    "    new AIMessage(\"Fine, thank you!\")\n",
    "  ]\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dd60bd2-fcc1-4f96-8763-969e30d52c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnablePassthrough } from \"langchain/runnables\";\n",
    "\n",
    "const conversationalRetrievalChain = RunnableSequence.from([\n",
    "  RunnablePassthrough.assign({\n",
    "    standalone_question: rephraseQuestionChain,\n",
    "  }),\n",
    "  RunnablePassthrough.assign({\n",
    "    context: documentRetrievalChain,\n",
    "  }),\n",
    "  answerGenerationChainPrompt,\n",
    "  new ChatOpenAI({ modelName: \"gpt-3.5-turbo\" }),\n",
    "  new StringOutputParser(),\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8f81c9f-88d7-470a-b597-c4137c9d35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnableWithMessageHistory } from \"langchain/runnables\";\n",
    "import { ChatMessageHistory } from \"langchain/stores/message/in_memory\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3b2e1ba-0419-4276-bdb4-3b044b3a7f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "const messageHistory = new ChatMessageHistory();\n",
    "\n",
    "const finalRetrievalChain = new RunnableWithMessageHistory({\n",
    "  runnable: conversationalRetrievalChain,\n",
    "  getMessageHistory: (_sessionId) => messageHistory,\n",
    "  historyMessagesKey: \"history\",\n",
    "  inputMessagesKey: \"question\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24bc88b0-851c-4304-a085-ac0cba9f615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are the prerequisites for the course listed in bullet point form:\n",
      "\n",
      "- Familiarity with basic probability and statistics\n",
      "- Familiarity with basic linear algebra\n",
      "- Some programming experience\n",
      "\n",
      "It is important to refer to the course information handout for more detailed information on these prerequisites.\n"
     ]
    }
   ],
   "source": [
    "const originalQuestion = \"What are the prerequisites for this course?\";\n",
    "\n",
    "const originalAnswer = await finalRetrievalChain.invoke({\n",
    "  question: originalQuestion,\n",
    "}, {\n",
    "  configurable: { sessionId: \"test\" }\n",
    "});\n",
    "\n",
    "const finalResult = await finalRetrievalChain.invoke({\n",
    "  question: \"Can you list them in bullet point form?\",\n",
    "}, {\n",
    "  configurable: { sessionId: \"test\" }\n",
    "});\n",
    "\n",
    "console.log(finalResult);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2133bd0-0e4d-4985-a62a-ee1a47fcba9e",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/fca11abd-c0ec-456f-800e-6edfaf6bcf68/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac36205-de1c-4cfb-81e8-9c9d1525b338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547772d-4f1f-48e8-b381-138b30d993af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25b85d-dd40-42a1-8374-6c778e86c9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af107da-cf4c-4900-a456-d131ff8fbc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcaa28f-5057-4109-80c1-406ec47bd9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b5f7d-75e0-4366-8adf-48053f19229d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50feff9-72d1-4c1a-96b9-ec80ccde87f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258343e5-e488-4c2c-938b-8c3189ef959d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec20e0c-389f-4cd1-b5df-67f6d706fb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2b76f-f963-4226-95f1-42d15487f0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a497d1-0587-431b-bc54-657e935af6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12805d9a-d5fe-48d5-acf3-d88a929e9d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d65826-7917-4a51-b937-37d3d460c5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc803c79-ef69-4539-b2eb-da3cd89cb134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4ed79-d80a-4d26-9832-1c13b7eb9085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f7da1-51d2-4bc8-8ea8-a76eb80a70cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838bf09-8369-4942-a78f-73a94b74d602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815c815-4354-46b7-b6fd-e4c2043176d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1e227-7b94-447d-a23f-dd10dbb5da15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416b2d4-d329-4876-8f47-981321c6c16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6736e91-bc01-4f17-a6ea-6cc455d6723c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10e4ed-1298-48bd-906e-00d585c1106a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f716a57-4284-4b82-a263-7d263dc5fdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169cb0c-a66d-487d-a9da-8aa834ebbd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67198cbc-9731-490a-85d2-4db5c8169735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629025a3-62df-497e-990b-dac252673994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b821d-4a8f-4319-a7e3-0e70982decbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2ef03-cbea-42ca-877e-b867936a3459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e56d1e-17e2-4c11-984a-da63e0d13e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
