{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Tutorial - Part 1: LLM Basic Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up OpenAI API\n",
    "\n",
    "Before starting this tutorial, please follow the steps below to set your environment:\n",
    "\n",
    "1. **Access the OpenAI Platform**:\n",
    "    - Visit [OpenAI Platform](https://platform.openai.com/).\n",
    "    - Go to [Settings > Billing](https://platform.openai.com/settings/organization/billing/overview) and add credits to your account (if necessary).\n",
    "    - Go to [Dashboard > API keys](https://platform.openai.com/api-keys) and generate a new API key.\n",
    "\n",
    "2. **Create an API Key**:    \n",
    "    - Create a new project (or use the Default project) and generate an API key.\n",
    "    - Add the key to you `.env` file using the following format:\n",
    "\n",
    "      ```\n",
    "      OPENAI_API_KEY=<your-secret-key>\n",
    "      ```\n",
    "\n",
    "3. **Load the `.env. File**:\n",
    "    - Make sure to properly load the `.env` file in your environment so the key is accessible to your application.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to Load the .env File\n",
    "\n",
    "**Important:**\n",
    "\n",
    "- Jupyter Notebooks and many Python extensions automatically load `.env` files.\n",
    "- The `python-dotenv` package reads key-value pairs from a `.env` file and can set them as environment variables.\n",
    "  - See: [python-dotenv GitHub repository](https://github.com/theskumar/python-dotenv)\n",
    "\n",
    "**Step 1: Install the Package `python-dotenv`**\n",
    "\n",
    "- From a terminal:\n",
    "  \n",
    "  ```\n",
    "  pip install python-dotenv\n",
    "  ```\n",
    "\n",
    "- Or from a Jupyter code cell:\n",
    "  \n",
    "  ```\n",
    "  !pip install python-dotenv\n",
    "  ```\n",
    "\n",
    "**Step 2: Load the `.env` File**\n",
    "\n",
    "- Using Python code:\n",
    "\n",
    "  ```python\n",
    "  from dotenv import load_dotenv\n",
    "  load_dotenv()\n",
    "  ```\n",
    "\n",
    "- Or using IPython extension from a Jupyter code cell:\n",
    "\n",
    "  ```python\n",
    "  %load_ext dotenv\n",
    "  %dotenv\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# override=False (default)\n",
    "# Whether to override the system environment variables with the variables from the '.env' file.\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Parse a .env file and return its content as a dict.\n",
    "# It does not set environment variables.\n",
    "dotenv_content = dotenv_values()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']\n",
    "TAVILY_API_KEY = dotenv_content['TAVILY_API_KEY']\n",
    "\n",
    "print(OPENAI_API_KEY)\n",
    "print(GOOGLE_API_KEY)\n",
    "print(TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages langchain and langchain_openai\n",
    "# Use the following syntax, with --upgrade, to upgrade the version of any package, if a new version is available\n",
    "!pip install --upgrade langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class ChatOpenAI from the package langchain_openai\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ChatOpenAI\n",
    "\n",
    "# ChatOpenAI is able to get the OPENAI_API_KEY from the system environment\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# If OPENAI_API_KEY is not defined, the api_key must be informed:\n",
    "# llm = ChatOpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First call to the llm\n",
    "llm.invoke(\"Tell me a joke.\")\n",
    "\n",
    "# Similar expected response:\n",
    "# AIMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 12, 'total_tokens': 25, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'text_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cd71b40d-ba77-4e15-bd35-7bb72a0aeb1a-0', usage_metadata={'input_tokens': 12, 'output_tokens': 13, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a professional prompt\n",
    "\n",
    "# Import the class ChatPromptTemplate from langchain_core.prompts\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ChatPromptTemplate using the from_messages class method\n",
    "# Without any input placeholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an excellent joke teller.\"),\n",
    "        (\"user\", \"Tell me a joke about politics.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple chain that:\n",
    "# - takes the prompt and passes it to the chat model to be processed by the llm\n",
    "# - and then returns the response\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain\n",
    "# Without any mapped input, passing an empty dictionaty {}\n",
    "ai_msg = chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of ai_msg\n",
    "type(ai_msg)\n",
    "\n",
    "# langchain_core.messages.ai.AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(ai_msg) == AIMessage\n",
    "ai_msg\n",
    "\n",
    "# Similar expected response:\n",
    "# AIMessage(content='Why did the politician go to the doctor? Because they heard it was a good way to get a second opinion!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 27, 'total_tokens': 50, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7bd6db23-301c-4a34-a108-477acc21acb4-0', usage_metadata={'input_tokens': 27, 'output_tokens': 23, 'total_tokens': 50, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of ai_msg.content\n",
    "type(ai_msg.content)\n",
    "\n",
    "# str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(ai_msg.content) == str\n",
    "ai_msg.content\n",
    "\n",
    "# Similar expected response:\n",
    "# Why did the politician go to the doctor? Because they heard it was a good way to get a second opinion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A prompt with user input (placeholder)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an excellent joke teller.\"),\n",
    "        (\"user\", \"Tell me a joke about {user_input}.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple chain\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain\n",
    "# Passing a dictionaty to supply the value for the placeholder 'user_input'\n",
    "ai_msg = chain.invoke({'user_input': 'dictatorships'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg\n",
    "\n",
    "# Similar expected response:\n",
    "# AIMessage(content='Why did the dictator go to the beach? \\n\\nTo catch some waves of oppression!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 22, 'total_tokens': 39, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2b6e4759-6dda-40c5-8c6f-4180d87b8cf9-0', usage_metadata={'input_tokens': 22, 'output_tokens': 17, 'total_tokens': 39, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other examples...\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a not helpful assistant who makes fun of anything.\"),\n",
    "        (\"user\", \"I would like to understand {user_input}. Can you tell me more about it?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "ai_msg = chain.invoke({'user_input': 'Earth Planet'})\n",
    "\n",
    "print(ai_msg.content)\n",
    "\n",
    "# Similar expected response:\n",
    "# Oh, you want to understand Earth, the big blue marble in space? Well, it's a pretty average planet, nothing too special. Just a little ball of rock and water floating around the sun. But hey, at least it's got some nice beaches, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a not helpful assistant who tells the opposite of the truth.\"),\n",
    "        (\"user\", \"I would like to understand {user_input}. Can you tell me more about it?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "ai_msg = chain.invoke({'user_input': 'Earth Planet'})\n",
    "\n",
    "print(ai_msg.content)\n",
    "\n",
    "# Similar expected response:\n",
    "# Sorry, I can't help you with that. Earth is a mysterious planet that no one really knows much about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"user\", \"I would like to understand {user_input}. Can you tell me more about it?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "ai_msg = chain.invoke({'user_input': 'Earth Planet'})\n",
    "\n",
    "print(ai_msg.content)\n",
    "\n",
    "# Similar expected response:\n",
    "# Of course! Earth is the third planet from the Sun in our solar system and is the only known planet to support life. It is often referred to as the \"Blue Planet\" because of its abundance of water, which covers about 71% of its surface. Earth has a diverse range of environments, including oceans, mountains, forests, deserts, and more.\n",
    "# The planet has a diameter of about 12,742 kilometers (7,918 miles) and is the fifth-largest planet in our solar system. Earth has a relatively thin atmosphere composed mainly of nitrogen (78%) and oxygen (21%), which is essential for supporting life as we know it.\n",
    "# Earth orbits the Sun at an average distance of about 150 million kilometers (93 million miles) and takes approximately 365.25 days to complete one orbit, resulting in a year. It also rotates on its axis, causing day and night cycles, with a full rotation taking about 24 hours, resulting in a day.\n",
    "# Earth is home to a wide variety of life forms, ranging from microscopic bacteria to complex organisms like plants, animals, and humans. The planet's diverse ecosystems provide habitats for countless species and play a crucial role in maintaining the balance of life on Earth.\n",
    "# Overall, Earth is a unique and fascinating planet that continues to be studied and explored by scientists to better understand its complexities and the interconnected systems that support life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using OpenAI, the LLM response is an object AIMessage\n",
    "# - Use the syntax `ai_msg.content` to obtain the the content string\n",
    "\n",
    "# When using Google Gemini, the response is always a string\n",
    "# - The `ai_msg` itself is already a string\n",
    "\n",
    "# This can be an issue when interoperating with different APIs through LangChain\n",
    "# We can use LangChain Output Parsers to solve this issue\n",
    "\n",
    "# An output parser will help standardize the output across different LLMs, making it easier to handle responses regardless of the model used\n",
    "\n",
    "# Let's use a simple output parser\n",
    "# Import the class StrOutputParser from the package langchain_core.output_parsers\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the latest chain by recreating it\n",
    "\n",
    "# Create a simple chain that:\n",
    "# - takes the prompt and passes it to the chat model to be processed by the llm\n",
    "# - and then takes the response and passes it to be processed by the output parser\n",
    "# - and then returns the response content\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# alternatively:\n",
    "# chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain\n",
    "ai_msg = chain.invoke({\"user_input\": \"Earth Planet\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of ai_msg\n",
    "type(ai_msg)\n",
    "\n",
    "# str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(msg) == str\n",
    "ai_msg\n",
    "\n",
    "# Similar expected response:\n",
    "# 'Certainly! Earth is the third planet from the Sun in our solar system and is the only known planet to support life. It has a diverse range of ecosystems, including oceans, forests, deserts, and more. Earth has a unique atmosphere that consists mainly of nitrogen and oxygen, which is essential for supporting life as we know it.\\n\\nThe planet has a solid outer layer called the crust, a semi-liquid layer beneath the crust called the mantle, and a solid inner core at its center. Earth is constantly changing due to processes like plate tectonics, erosion, and volcanic activity.\\n\\nEarth is also known as the \"Blue Planet\" because of its abundance of water, which covers about 71% of its surface. The planet has a rich biodiversity, with millions of species of plants, animals, and microorganisms inhabiting its various environments.\\n\\nOverall, Earth is a fascinating and dynamic planet that provides a home for a wide variety of life forms.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output parser has already extracted the content from the AIMessage object\n",
    "# The ai_msg contains a string now\n",
    "# The code below will fail\n",
    "ai_msg.content\n",
    "\n",
    "# AttributeError: 'str' object has no attribute 'content'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
